:slug: machine-learning-vuln/
:date: 2018-11-07
:subtitle: Pueden las máquinas aprender a hackear?
:category: ataques
:tags: detectar, seguridad, vulnerabilidad
:image: cover.png
:alt: Robot con máscara de Hacker
:description: Un repaso rápido de las técnicas de machine learning aplicadas a la detección de vulnerabilidades en código fuente, basándose en artículos del 2011 al 2018. Los enfoques son agrupados como detección de anomalías, análisis de meta-código y reconocimiento de patrones.
:keywords: Machine learning, Vulnerabilidad, Detección de Anomalías, Reconocimiento de patrones, Deep learning, Seguridad
:author: Rafael Ballestas
:writer: raballestasr
:name: Rafael Ballestas
:about1: Matemático
:about2: con interés por CS
:source-highlighter: pygments
:translate: machine-learning-hack/

= Machine-learning para hackear

Para citar las
link:../vulnerabilidad-libssh/[vulnerabilidades]
link:../../../en/blog/treacherous-poodle/[de seguridad]
link:../../../en/blog/release-the-beast/[más]
link:../../../en/blog/my-heart-bleeds/[importantes]
han sido encontradas a través de una audioría exhaustiva de código.
Ésta es la única forma en que las vulnerabilidades
pueden ser encontradas y corregidas durante el desarrollo.
Sin embargo, al incrementarse las tasas de producción de software,
también se incrementa la necesidad de métodos automáticos confiables
para verificar o clasificar el código priorizando y orientando
los esfuerzos humanos en la verificación manual.
Vivimos en una era donde el +machine learning+ juega un
link:https://www.forbes.com/sites/forbestechcouncil/2018/09/27/15-business-applications-for-artificial-intelligence-and-machine-learning/#1ac831c579f2[papel importante]
en muchos otros campos tecnológicos,
¿Qué tal si lo aplicamos a nuestro apetito de búsqueda de errores?

// define focus
En este artículo y los siguientes,
nos enfocaremos en el uso de técnicas de +machine learning+ (+ML+)
para la búsqueda de vulnerabilidades en código fuente.
Es importante aclarar esto debido a que,
como veremos más adelante,
existen muchos otros enfoques que pueden estar relacionados,
pero que no se ajustan exactamente a esta definición, tales como:

// out of focus
- Auto correcciones
- Detección de vulnerabilidades (+VD+) en código binario.
Queremos asistir la revisión manual de código
hecha en código legible por humanos.
- Pruebas dinámicas asistidas por +ML+.
- Otras técnicas automáticas que no involucran +ML+.
- Predicción de explotabilidad.
Una vez más, solo queremos descubrirlos para revisarlos
y explotarlos manualmente más adelante.

// present main refs
La idea de utilizar técnicas de +ML+ para +VD+ no es nueva.
Existen artículos al respecto que datan del +2001+.
Aquí trataremos de describir en términos sencillos:

- lo que se ha hecho en esta área,
- el estado del arte actual y
- tratar de dilucidar nuevas rutas de investigación

Estaremos siguiendo y construyendo nuestro estado del arte basándonos
en dos artículos del estado del arte anterior
realizados por _Abraham y de Vel_ (+2017+)<<r1 ,^[1]^>> y
_Ghaffarian y Shahriari_ (+2017+)<<r2 ,^[2]^>>,
agregando los artículos y proyectos que se han realizado durante el último año.

// categories
Los enfoques para aplicar +ML+ en la +VD+ pueden ser clasificados:

- por el tipo de técnica de +ML+ utilizada
- por el grado de automatización
- por el tipo de código en el que se aplica, o
- por las características que son extraídas en la entrada
o deseadas como salida, por ejemplo,
lo que queremos buscar dentro del código
y que la máquina aprenda de ello.

Sentimos que este último enfoque tiene más sentido, al igual que <<r2 ,[2]>>,
quienes luego los clasifican de acuerdo a si se analiza
la sintaxis y la semántica del programa,
los que lo hacen son subdivididos en dos categorías principales:

- Reconocimiento de patrones de código vulnerable.
Usualmente basado en datos con etiquetas
(muestras de código seguro y vulnerable)
determinar patrones que explican eso, y

- Detección de anomalías.
Esto significa, extraer modelos a partir de una extensa base de códigos
de cómo debería lucir un "código normal" y determinar piezas de código
que no se ajustan a este modelo.

== Enfoque de detección de anomalías

La mayoría de los artículos en esta categoría
no están enfocados en la seguridad,
pero sus ideas pueden ser utilizadas para la +VD+.
De igual manera, la mayoría de estos trabajos giran alrededor
de extraer características, tales como:

- Uso de patrones API adecuados,
es decir, las parejas +malloc+ y +free+,
- Revisiones faltantes, como asegurar que un número sea diferente de cero
antes de ser divido.
- Falta de validación de entradas,
lo cual puede conducir a inyecciones, +buffer overflows+ ...
- Falta de controles de acceso,
lo cual puede generar fugas de información confidencial,
alteración de información, o denegación de accesos.

Estos enfoques también han sido utilizados
en el control de calidad de software, ya que
pueden proveer, como un bonus,
la extracción automática de especificaciones, reglas y patrones,
un proceso laborioso y propenso a errores si se hace a mano.
De ahí la mezcla con artículos no relacionados a la seguridad en esta área.

// star chucky
El sistema link:http://chucky.readthedocs.io/en/latest/[Chucky] de
link:https://user.informatik.uni-goettingen.de/~krieck/docs/2013-ccs.pdf[Yamaguchi et al. (2013)]
es el que más nos interesa
ya que es el más compatible con nuestro enfoque,
es decir, aligerar la carga de los auditores de código manuales;
de igual manera, ellos logran los objetivos mencionados anteriormente:
detectar revisiones faltantes
a través de lógica de seguridad (es decir, control de acceso)
y utilización segura de +APIs+ (es decir, revisión de tamaño de buffer)
Utiliza el modelo de link:https://en.wikipedia.org/wiki/Bag-of-words_model[[red]#bolsa de palabras#]
para representar el código y la técnica de los
link:https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm[[red]#k-vecinos más cercanos#]
para analizarlo.
Un gráfico especial propuesto por los mismos autores,
llamado el _Gráfico de propiedad de código_
el cual combina otras representaciones gráficas del código, como
el link:../oracle-code/#databases-out-of-programs[árbol abstracto de sintaxis],
el link:http://research.cs.wisc.edu/wpis/papers/icse92.pdf#page=4[gráfico de dependencias]
y el link:https://scitools.com/feature/control-flow-graphs/[gráfico de control de flujo],
es almacenado en la base de datos orientada a gráficos link:https://neo4j.com/[neo4j]
y puede ser combinado con el lenguaje de consulta de gráficos link:http://tinkerpop.apache.org/docs/current/reference/[Gremlin].
+Chucky+ descubrió +12+ nuevas vulnerabilidades
en proyectos de alto perfil, como
link:https://pidgin.im/[Pidgin] y link:http://libtiff.org/[LibTIFF].

// also joern
Un año después,
link:https://www.sec.cs.tu-bs.de/pubs/2014-ieee.pdf[Yamaguchi et al. (2014)]
reutilizaron esta idea de explotar representaciones gráficas de código
para encontrar patrones de código vulnerable.
Esta vez propusieron automatizar el diseño de transversales efectivos
lo cual puede llevar a la detección de vulnerabilidades
utilizando el enfoque de link:https://en.wikipedia.org/wiki/Cluster_analysis[[red]#clustering#]
no supervisado.
Esto resultó en la herramienta link:http://www.mlsec.org/joern/['Joern'],
la cual fue capaz de encontrar +5+ vulnerabilidades de día cero
en productos como +Pidgin+.

// mention a couple more?
La mayoría de artículos en esta categoría no están enfocados en la seguridad.
Todos ellos utilizan link:https://en.wikipedia.org/wiki/Association_rule_learning[minería de elementos frecuentes],
con diferentes características para minar
y diferentes objetivos a extraer.
Los resumimos aquí con el fin de completar nuestro artículo:

// tabularize
.Otros enfoques de búsqueda de anomalías
[cols="3"]
|=======================
| *Artículo* | *Elementos minados* | *Objetivo*
| link:http://www.doc.ic.ac.uk/~livshits/papers/pdf/dynamine_ext.pdf[Livshits and Zimmermann (2005)]
| +commit logs+                | patrones específicos de la aplicación
| link:https://www.cs.purdue.edu/homes/xyzhang/fall07/Papers/PRMiner.pdf[Li and Zhou (2005)]
| código fuente               | reglas implícitas de código
| link:https://www.st.cs.uni-saarland.de/edu/recommendation-systems/papers/p35-wasylkowski-1.pdf[Wasylowski et al. (2007)]
| secuencias de llamado de funciones    | modelos de uso de objetos
| link:https://www.cs.sfu.ca/~jpei/publications/APIMining_FSE07.pdf[Acharya et al. (2007)]
| Trazas de uso de APIs           | Órdenes de uso de APIs
| link:https://www.computer.org/csdl/journal/ts/2008/05/tts2008050579/13rRUxAAT2W[Chang et al. (2008)]
| Condicionales descuidados       | reglas implícitas de condicionales
| link:https://link.springer.com/article/10.1007/s10515-011-0086-z[Thummalapenta et al (2009)]
| Reglas de programación          | patrones alternativos
| link:https://www.st.cs.uni-saarland.de/publications/files/gruska-issta-2010.pdf[Gruska et al (2010)]
| Llamados a funciones             | Anomalías de proyectos cruzados
|=======================


// conclude anomalies
En términos generales, el enfoque de detección anomalías
tiene las siguientes limitaciones:

- solo aplican a software maduro,
donde asumimos que el uso incorrecto de APIs son ocurrencias raras,
- el uso particular debe ser relativamente frecuente
en la base del código para ser identificado como una anomalía
(de lo contrario, la regla se vuelve la norma)
- Generalmente no pueden identificar el tipo de vulnerabilidad,
o incluso _si_ la anomalía es una vulnerabilidad de seguridad,
solo lo identifican como un elemento desviado.
- Las tasas de falsos positivos son generalmente altas.

== Enfoque de reconocimiento de patrones

El objetivo es tomar un gran conjunto de datos
de muestras de vulnerabilidades
y extraer patrones de código vulnerable
utilizando algoritmos de +machine learning+
(normalmente link:https://en.wikipedia.org/wiki/Supervised_learning[[red]#supervisados#]).
La clave es la técnica utilizada para extraer características,
las cuales van desde los link:../pars-oraciones-seguro/[intérpretes] convencionales,
pasando por el análisis de flujo de datos y flujo de control
e incluso minando directamente el texto del código fuente.
La mayoría de artículos utilizan algoritmos de
link:https://en.wikipedia.org/wiki/Statistical_classification[[red]#clasificación#]

// yama14 extrapol
Una vez más Yamaguchi et al.
(link:https://media.blackhat.com/bh-us-11/Yamaguchi/BH_US_11_Yamaguchi_Vulnerability_Extrapolation_WP.pdf[2011],
link:https://www.researchgate.net/publication/233997025_Generalized_Vulnerability_Extrapolation_using_Abstract_Syntax_Trees[2012]) toman la delantera,
imitando el proceso mental detrás de la rutina diaria del auditor de código:
buscando instancias similares de vulnerabilidades (recientes)
descubiertas previamente.
Ellos llaman a esto _extrapolación de vulnerabilidades_.
Esencialmente: interpretar e incrustar en una vector de espacio
utilizando un método similar a la bolsa de palabras,
ejecutar un análisis semántico para obtener matrices particulares,
y luego compararlas con código vulnerable conocido utilizando
link:https://en.wikipedia.org/wiki/Similarity_learning[[red]#funciones de distancia#] estándar.

// others
Otros enfoques en esta categoría son los de
link:https://core.ac.uk/download/pdf/34611720.pdf[Scandariato et al. (2014)] y
link:https://www.researchgate.net/publication/300414677_Predicting_Vulnerable_Software_Components_through_N-Gram_Analysis_and_Statistical_Feature_Selection[Pang et al. (2015)],
los cuales intentan utilizar técnicas
tales como análisis +n-gram+ utilizando bolsa de palabras,
con resultados limitados,
probablemente debido a la información superficial y simpleza de los métodos.

// vdiscover
link:http://www.vdiscover.org/[VDiscover] no se ajusta exactamente a nuestra definición
pero cabe mencionarlo.
Ellos identifican cada rastro del llamado a la librería estándar de +C+
como un documento de texto y lo procesan como un
link:https://en.wikipedia.org/wiki/N-gram[[red]#n-grama#]
y lo codifican con
link:https://en.wikipedia.org/wiki/Word2vec[[red]#word2vec#].
Ellos han probado diferentes técnicas de +ML+ tales como la
link:https://en.wikipedia.org/wiki/Logistic_regression[[red]#regresión logística#],
el link:https://en.wikipedia.org/wiki/Multilayer_perceptron[[red]#MLP#]
y los link:https://en.wikipedia.org/wiki/Random_forest[[red]#bosques aleatorios#].

En los últimos meses,
han aparecido algunos artículos que entran en nuestro alcance.
_Li et al._ propone dos sistemas:
link:https://arxiv.org/pdf/1801.01681.pdf[VulDeePecker (2018a)] y
link:https://arxiv.org/abs/1807.06756v2[SySeVR (2018b)],
el cual pretende extraer información sintáctica y semántica del código
en forma de _porciones de programa_,
de esta manera también se considera tanto el flujo de control como los datos.
Esta información es codificada como vectores utilizando +word2vec+,
e introducida a diferentes
link:https://en.wikipedia.org/wiki/Artificial_neural_network[[red]#redes neuronales#].
Ellos reportan buenos resultados con pocos falsos positivos
y +15+ vulnerabilidades de día cero en librerías +FOSS+ de alto perfil.
Sin embargo, estos artículos:

- necesitan revisión de pares, ya que están en estado de pre-impresión o
son artículos de conferencia
- están diseñados exclusivamente para código base en C(++)
- están sujetos a las limitaciones de otros sistemas,
como la granularidad gruesa.

link:https://dl.acm.org/citation.cfm?id=3138840[_Lin et al. (2017)_]
proponen una variante
la cual simplifica la extracción de características
volviendo solo a +AST+ sin información semántica
utilizando
link:https://en.wikipedia.org/wiki/Deep_learning[[red]#deep learning#]
en forma de
link:https://en.wikipedia.org/wiki/Long_short-term_memory[[red]#redes bidireccionales de memoria a corto y largo plazo (BLSTM)#],
con un elemento completamente nuevo:
A diferencia de la mayoría de trabajos anteriores,
los cuales funcionan en el dominio interno del proyecto
(lo cual nos recuerda constantemente _Ghaffarian et al._),
+POSTER+ involucra métricas de software (ver abajo)
para compararlo con otros proyectos.

// conclude patterns
A pesar de que estos enfoques parecen interesantes,
no están exentos de limitaciones:

- La mayoría de estos modelos
no permiten identificar el tipo de vulnerabilidad.
Sólo reconocen patrones de código vulnerable.
Esto significa también que no localizan el punto exacto
del error potencial.

- Cualquier trabajo de +machine learning+
enfocado en la detección de vulnerabilidades
debería tener en cuenta varios aspectos del código
para descripciones más completas,
tales como la sintaxis, la semántica
y el flujo de datos y de control,

- Se cree que la calidad de los resultados
se debe principalmente a las características que se extraen
y alimentan los algoritmos de aprendizaje.
Ghaffarian llama a esto _ingeniería de características_.
Las características extraídas de representaciones gráficas,
según ellos, no han sido completamente explotadas.

- Los algoritmos de +machine learning+ no supervisados,
especialmente los de +deep learning+ no son utilizados lo suficiente,
a pesar de que ésto ha empezado a cambiar en los últimos años.

== Otros enfoques

Las métricas de software como:

- link:https://en.wikipedia.org/wiki/Source_lines_of_code[tamaño] (líneas lógicas de código),
- link:https://en.wikipedia.org/wiki/Cyclomatic_complexity[complejidad ciclomática],
- link:http://iedaddy.com/2017/09/devops-metrics-code-churn/[cambios en las líneas] y
- actividad del desarrollador

Se han propuesto como _predictores_
para la presencia de vulnerabilidades en el software de proyectos.
Estos estudios utilizan en su mayoría
procedimientos basados en fuentes de vulnerabilidades disponibles públicamente,
tales como  link:https://nvd.nist.gov/[NVD],
con excepción de
link:https://www.sciencedirect.com/science/article/pii/S1361372313700459[Moshtari et al. (2013)],
quienes propusieron un +framework+ semi automático y auto-contenido.
También cabe destacar a
link:https://saschafahl.de/papers/vccfinder2015.pdf[VCCFinder]
por _Perl et al. (2015)_,
el cual trabaja a nivel de repositorio
para encontrar +commits+ que contribuyen a una vulnerabilidad (+VCCs+)

De acuerdo a <<r2 ,[2]>> y a
link:https://faculty.cs.nku.edu/~waldenj/papers/issre2014-php-prediction.pdf[Walden et al. (2014)],
predecir la existencia de vulnerabilidades
basándose en métricas de ingeniería de software puede ser difícil,
ya que puede generar _causas y síntomas confusos_:

image::https://imgs.xkcd.com/comics/correlation.png[XKCD on correlation]

Esto significa que puede existir una correlación
entre ciertas métricas y la presencia de vulnerabilidades,
pero no nos dice nada sobre la presencia de vulnerabilidades en general.
La mayoría de los artículos revisados en esta categoría
presentan altas tasas de falsos positivos
y solamente uno de ellos exploró técnicas automatizadas.
Por lo tanto los consideramos menos interesantes para nuestros propósitos.

link:https://bit.ly/2qBzPTZ[Wijayasekara et al (2012, 2014)]
se enfocan en el minado de texto de bases de datos públicas de vulnerabilidades
lo cual parece una buena idea, para encontrar +bugs+ de impacto oculto,
por ejemplo +bugs+ que han sido reportados,
pero cuyas implicaciones de seguridad ignoramos.
Muchos otros autores se enfocan en el uso de
link:https://en.wikipedia.org/wiki/Genetic_algorithm[algoritmos genéticos] y
otras técnicas de _inteligencia artificial/computacional_
las cuales están por fuera del alcance de este artículo.
link:https://www.acsac.org/2007/papers/22.pdf[Sparks et al. (2007)],
link:https://www.researchgate.net/publication/260730962_Applications_of_computational_intelligence_for_static_software_checking_against_memory_corruption_vulnerabilities[Alvares et al.(2013)],
link:http://www.gsd.inesc-id.pt/~mpc/pubs/fp694-medeiros.pdf[Medeiros et al. (2014)]
Se enfocaron en clasificar vulnerabilidades reportadas
utilizando técnicas de +ML+,
pero no en su descubrimiento.

''''

// general conclusions

Ese fue el panorama del +machine learning+
en las investigaciones sobre vulnerabilidades de software
para finales del 2018.
Algunas limitaciones comunes son:

- El problema de encontrar vulnerabilidades
es _indecidible_ en vista del
link:https://en.wikipedia.org/wiki/Rice%27s_theorem[Teorema de Rice],
por ejemplo, un algoritmo universal para encontrar vulnerabilidades
no puede existir, ya que un programa no puede identificar
propiedades semánticas de otro programa en un caso general.

- Aplicabilidad limitada. Debido a que la técnica sólo aplica
a sistemas maduros o un lenguaje en particular,
sería interesante tener técnicas con un espectro más grande.

- Granularidad gruesa y falta de explicaciones.
La mayoría de los sistemas revisados solo pueden afirmar que
_este programa tiene una vulnerabilidad_,
pero nos gustaría conocer la línea o la función donde aparece,
qué tipo de vulnerabilidad es, y qué la causa
para mejorar la asignación de recursos humanos
en la revisión de código subsecuente.

- Un mayor grado de automatización es deseable,
no para reemplazar la auditorpia manual de código, sino para guiarla.
Los enfoques puramente automáticos son, de acuerdo al teorema de Rice,
imposibles o mal encaminados.

== Referencias

. [[r1]] T. Abraham and O. de Vel (2017).
'A Review of Machine Learning in Software Vulnerability Research'.
link:https://www.dst.defence.gov.au/sites/default/files/publications/documents/DST-Group-GD-0979.pdf[DST-Group-GD-0979].
Australian department of defence.

. [[r2]] S. Ghaffarian and H. Shahriari (2017).
link:https://dl.acm.org/citation.cfm?id=3092566[Software Vulnerability Analysis
and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey].
'ACM Computing Surveys (CSUR)' 50 (4)
