# Standard libraries
import html
import json
import os
import uuid
from itertools import chain
from operator import itemgetter
from typing import (
    Awaitable,
    cast,
    Dict,
    List,
    Optional,
)
from urllib.parse import urlparse

# Third-party libraries
import yaml
from aioextensions import collect
from graphql.type.definition import GraphQLResolveInfo
from pykwalify.core import Core
from pykwalify.errors import (
    CoreError,
    SchemaError,
)
from starlette.datastructures import UploadFile

# Local libraries
from backend import util
from backend.exceptions import (
    InvalidFileSize,
    InvalidPath,
    InvalidPort,
    InvalidSchema,
    InvalidSpecific,
    InvalidStream,
    InvalidVulnsNumber,
)
from backend.typing import (
    Finding as FindingType,
    User as UserType,
    Vulnerability as VulnerabilityType,
)
from findings import domain as findings_domain
from newutils import (
    datetime as datetime_utils,
    vulnerabilities as vulns_utils,
)
from roots import domain as roots_domain
from vulnerabilities import (
    dal as vulns_dal,
    domain as vulns_domain,
)


async def _validate_roots(
    *,
    group_name: str,
    vulnerabilities: Dict[str, List[Dict[str, str]]]
) -> None:
    nicknames = set(
        vuln['repo_nickname']
        for vulns in vulnerabilities.values()
        for vuln in vulns
        if 'repo_nickname' in vuln
    )
    await collect(
        tuple(
            roots_domain.get_root_by_nickname(
                group_name=group_name,
                repo_nickname=nickname
            )
            for nickname in nicknames
        )
    )


async def add_vuln_to_dynamo(
    *,
    item: Dict[str, str],
    specific: str,
    finding_id: str,
    info: GraphQLResolveInfo,
    vulnerability: Optional[Dict[str, FindingType]]
) -> bool:
    """Add vulnerability to dynamo."""
    historic_state = []
    response = False
    current_day = datetime_utils.get_now_as_str()
    user_data = cast(UserType, await util.get_jwt_content(info.context))
    email = str(user_data['user_email'])
    if vulnerability:
        return await vulns_domain.update_vuln_state(
            info,
            vulnerability,
            item,
            finding_id,
            current_day
        )

    data: Dict[str, FindingType] = {'repo_nickname': item['repo_nickname']}
    source = util.get_source(info.context)
    new_state: Dict[str, str] = {
        'analyst': email,
        'date': current_day,
        'source': source
    }
    data['historic_treatment'] = [{
        'date': current_day,
        'treatment': 'NEW'
    }]
    data['vuln_type'] = item.get('vuln_type', '')
    data['where'] = item.get('where', '')
    data['specific'] = specific
    data['finding_id'] = finding_id
    if 'stream' in item:
        data['stream'] = item['stream']
    if 'commit_hash' in item:
        data['commit_hash'] = item['commit_hash']
    data['UUID'] = str(uuid.uuid4())
    if item.get('state'):
        new_state['state'] = item['state']
        historic_state.append(new_state)
        data['historic_state'] = historic_state
        response = await vulns_dal.create(data)
    else:
        util.cloudwatch_log(
            info.context,
            'Security: Attempted to add vulnerability without state'
        )
    return response


async def get_vulns_to_add(
    vulnerabilities: Dict[str, List[VulnerabilityType]],
) -> List[Dict[str, str]]:
    coroutines = []
    for vuln_type in ['inputs', 'lines', 'ports']:
        file_vuln = vulnerabilities.get(vuln_type)
        if file_vuln:
            coroutines.extend([
                map_vulnerability_type(vuln, vuln_type)
                for vuln in file_vuln
            ])
        else:
            pass
            # If a file does not have a type of vulnerabilities,
            # this does not represent an error or an exceptional condition.
    return list(chain.from_iterable(await collect(coroutines)))


async def map_vulnerability_type(
    item: VulnerabilityType,
    vuln_type: str,
) -> List[Dict[str, str]]:
    """Add vulnerability to dynamo."""
    response = []
    where_headers = {
        'inputs': {'where': 'url', 'specific': 'field'},
        'lines': {'where': 'path', 'specific': 'line'},
        'ports': {'where': 'host', 'specific': 'port'}
    }

    data: Dict[str, str] = {
        'repo_nickname': item.get('repo_nickname'),
        'state': str(item.get('state', '')),
        'vuln_type': vuln_type
    }
    data['where'] = str(item.get(where_headers[vuln_type]['where']))
    specific = str(item.get(where_headers[vuln_type]['specific']))

    if vuln_type == 'lines' and data['where'].find('\\') >= 0:
        path = data['where'].replace('\\', '\\\\')
        raise InvalidPath(expr=f'"values": "{path}"')
    if 'stream' in item:
        validate_stream(data['where'], str(item['stream']))
        data['stream'] = str(item['stream'])
    if 'commit_hash' in item:
        data['commit_hash'] = str(item['commit_hash'])
    if vulns_utils.is_range(specific) or vulns_utils.is_sequence(specific):
        response.extend(
            ungroup_vulnerability_specific(vuln_type, specific, data)
        )
    else:
        if vuln_type == 'ports' and not 0 <= int(specific) <= 65535:
            raise InvalidPort(expr=f'"values": "{specific}"')
        response.append({**data, 'specific': specific})
    return response


async def map_vulns_to_dynamo(
    info: GraphQLResolveInfo,
    vulnerabilities: Dict[str, List[VulnerabilityType]],
    finding: Dict[str, FindingType]
) -> bool:
    """Map vulnerabilities and send it to dynamo."""
    coroutines: List[Awaitable[bool]] = []
    finding_id = finding.get('finding_id', '')
    vulns_to_add = await get_vulns_to_add(vulnerabilities)
    if len(vulns_to_add) > 100:
        raise InvalidVulnsNumber()

    finding_vulns = await vulns_dal.get_by_finding(str(finding_id))
    vulns: List[Dict[str, FindingType]] = [
        next(
            iter([
                vuln
                for vuln in finding_vulns
                if (
                    vuln_to_add.get('vuln_type', '') ==
                    vuln.get('vuln_type', '_') and
                    vuln_to_add.get('where', '') == vuln.get('where', '_') and
                    vuln_to_add.get('specific', '') ==
                    vuln.get('specific', '_')
                )
            ]),
            {}
        )
        for vuln_to_add in vulns_to_add
    ]

    closed_vulns_to_reattack: List[Dict[str, str]] = sorted(
        [
            {
                **vuln_to_add,
                'UUID': str(vuln['UUID'])
            }
            for vuln, vuln_to_add in zip(vulns, vulns_to_add)
            if (
                vulns_utils.is_reattack_requested(vuln) and
                vulns_utils.get_last_status(vuln) == 'open' and
                vuln_to_add.get('state') == 'closed'
            )
        ],
        key=itemgetter('UUID')
    )
    closed_vulns_uuids = {vuln['UUID'] for vuln in closed_vulns_to_reattack}

    coroutines.extend([
        add_vuln_to_dynamo(
            item=vuln_to_add,
            specific=str(vuln_to_add.get('specific')),
            finding_id=str(finding_id),
            info=info,
            vulnerability=vuln,
        )
        for vuln_to_add, vuln in zip(vulns_to_add, vulns)
        if str(vuln.get('UUID', '')) not in closed_vulns_uuids
    ])
    if closed_vulns_to_reattack:
        user_data = cast(UserType, await util.get_jwt_content(info.context))
        coroutines.append(
            findings_domain.verify_vulnerabilities(
                info=info,
                finding_id=str(finding_id),
                user_info=user_data,
                parameters={
                    'justification': 'The vulnerability was verified'
                                     ' by closing it',
                    'closed_vulns': list(closed_vulns_uuids),
                },
                vulns_to_close_from_file=closed_vulns_to_reattack,
            )
        )
    return all(await collect(coroutines))


async def process_file(
    info: GraphQLResolveInfo,
    file_input: UploadFile,
    finding: Dict[str, FindingType]
) -> bool:
    """Process a file."""
    success = False
    finding_id = finding.get('finding_id', '')
    group_name: str = finding['project_name']
    raw_content = await file_input.read()
    raw_content = cast(bytes, raw_content).decode()
    file_content = html.escape(raw_content, quote=False)
    await file_input.seek(0)
    vulnerabilities = yaml.safe_load(file_content)
    file_url = f'/tmp/vulnerabilities-{uuid.uuid4()}-{finding_id}.yaml'
    with open(file_url, 'w') as stream:
        yaml.safe_dump(vulnerabilities, stream)
    if validate_file_schema(file_url, info):
        await _validate_roots(
            group_name=group_name,
            vulnerabilities=vulnerabilities
        )
        success = await map_vulns_to_dynamo(info, vulnerabilities, finding)
    else:
        success = False
    return success


def ungroup_vulnerability_specific(
    vuln: str,
    specific: str,
    data: Dict[str, str]
) -> List[Dict[str, str]]:
    """Add vulnerability auxiliar."""
    if vuln in ('lines', 'ports'):
        specific_values = vulns_utils.ungroup_specific(specific)
    else:
        specific_values = [
            spec
            for spec in specific.split(',')
            if spec
        ]
    if (
        vuln == 'ports' and not
        all((0 <= int(i) <= 65535) for i in specific_values)
    ):
        error_value = f'"values": "{specific}"'
        raise InvalidPort(expr=error_value)
    if not specific_values:
        raise InvalidSpecific()
    return [
        {
            **data,
            'specific': specific
        }
        for specific in specific_values
    ]


async def upload_file(
    info: GraphQLResolveInfo,
    file_input: UploadFile,
    finding: Dict[str, FindingType]
) -> bool:
    mib = 1048576
    success = False
    if await util.get_file_size(file_input) < 1 * mib:
        success = await process_file(info, file_input, finding)
    else:
        raise InvalidFileSize()
    return success


def validate_file_schema(file_url: str, info: GraphQLResolveInfo) -> bool:
    """Validate if a file has the correct schema."""
    schema_dir = os.path.dirname(os.path.abspath(__file__))
    schema_dir = os.path.join(schema_dir, 'vuln_template.yaml')
    core = Core(source_file=file_url, schema_files=[schema_dir])
    is_valid = False
    try:
        core.validate(raise_exception=True)
        is_valid = True
    except SchemaError:
        lines_of_exceptions = core.errors
        errors_values = [
            getattr(x, 'pattern', '')
            for x in lines_of_exceptions
            if not hasattr(x, 'key')
        ]
        errors_keys = [
            x
            for x in lines_of_exceptions
            if hasattr(x, 'key')
        ]
        errors_values_formated = [json.dumps(x) for x in errors_values]
        errors_keys_formated = [
            f'"{x.key}"'
            for x in errors_keys
        ]
        errors_keys_joined = ','.join(errors_keys_formated)
        errors_values_joined = ','.join(errors_values_formated)
        error_value = (
            f'"values": [{errors_values_joined}], '
            f'"keys": [{errors_keys_joined}]'
        )
        util.cloudwatch_log(
            info.context,
            'Error: An error occurred validating vulnerabilities file'
        )
        raise InvalidSchema(expr=error_value)
    except CoreError:
        raise InvalidSchema()
    finally:
        os.unlink(file_url)
    return is_valid


def validate_stream(where: str, stream: str) -> bool:
    url_parsed = urlparse(where)
    if len(url_parsed.path) == 0 or url_parsed.path == '/':
        if stream.lower().startswith('home,'):
            return True
        raise InvalidStream()
    return True
