image: registry.gitlab.com/fluidsignal/serves:builder

before_script:
  - export DOCKER_BASENAME="$CI_REGISTRY/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME"
  - echo "$CI_REGISTRY_PASSWORD" |
        docker login "$CI_REGISTRY" -u "$CI_REGISTRY_USER" --password-stdin

after_script:
  - docker logout "$CI_REGISTRY"

stages:
  - deps
  - test-code
  - test-infra
  - build
  - tag
  - deploy
  - postdeploy
  - dns
  - rotation
  - backup

.vault_login: &vault_login
  before_script:
    - export VAULT_TOKEN=$(curl --request POST
        --data '{"role_id":"'"$SERVES_ROLE_ID"'","secret_id":"'"$SERVES_SECRET_ID"'"}'
        "https://$VAULT_S3_BUCKET.com/v1/auth/approle/login" |
        jq -r '.auth.client_token')
    - export VAULT_HOST="$VAULT_S3_BUCKET.com"
    - export VAULT_PORT=443
    - export VAULTENV_SECRETS_FILE="$CI_PROJECT_DIR/env.vars"
    - export DOCKER_BASENAME="$CI_REGISTRY/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME"
    - echo "$CI_REGISTRY_PASSWORD" |
        docker login "$CI_REGISTRY" -u "$CI_REGISTRY_USER" --password-stdin

.kaniko_config: &kaniko_config
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  before_script:
    - echo '{"auths":{"'"${CI_REGISTRY}"'":{"username":"'"${CI_REGISTRY_USER}"'","password":"'"${CI_REGISTRY_PASSWORD}"'"}}}'
        > /kaniko/.docker/config.json

.vault_vars: &vault_vars
  variables:
    VAULT_HOST: "${VAULT_S3_BUCKET}.com"
    VAULT_PORT: 443
    VAULT_API_URL: "https://${VAULT_S3_BUCKET}.com/v1/auth/approle/login"
    ROLE_ID: "${SERVES_ROLE_ID}"
    SECRET_ID: "${SERVES_SECRET_ID}"

.kaniko_vault_config: &kaniko_vault_config
  <<: *vault_vars
  <<: *kaniko_config

.dind_config: &dind_config
  variables:
    DOCKER_DRIVER: overlay2
  services:
    - docker:dind

build_base:
  stage: deps
  <<: *kaniko_config
  script:
    - /kaniko/executor
        --context "${CI_PROJECT_DIR}/containers/base/"
        --dockerfile "${CI_PROJECT_DIR}/containers/base/Dockerfile"
        --destination "${CI_REGISTRY_IMAGE}:base"
  only:
    - schedules

build_builder:
  stage: deps
  <<: *kaniko_config
  script:
    - /kaniko/executor
        --context "${CI_PROJECT_DIR}/containers/builder/"
        --dockerfile "${CI_PROJECT_DIR}/containers/builder/Dockerfile"
        --destination "${CI_REGISTRY_IMAGE}:builder"

test_code:
  stage: test-code
  script:
    - ./check-changed.sh
  except:
    - master

test_terraform:
  stage: test-infra
  <<: *vault_login
  script:
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/terraform.tfstate
        infrastructure/terraform.tfstate ||
        echo "No previous state for infrastructure found"
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/dns/terraform.tfstate
        infrastructure/dns/terraform.tfstate ||
        echo "No previous state for DNS found"
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/staging/terraform.tfstate
        infrastructure/staging/terraform.tfstate ||
        echo "No previous state for staging found"
    - vaultenv infrastructure/terraform.sh
  after_script:
    - rm infrastructure/*.xml
    - docker logout "$CI_REGISTRY"
  except:
    - master

build_alg:
  stage: build
  <<: *kaniko_vault_config
  script:
    - cp env.vars containers/alg/
    - /kaniko/executor
        --build-arg VAULT_HOST="${VAULT_HOST}"
        --build-arg VAULT_PORT="${VAULT_PORT}"
        --build-arg VAULT_API_URL="${VAULT_API_URL}"
        --build-arg ROLE_ID="${ROLE_ID}"
        --build-arg SECRET_ID="${SECRET_ID}"
        --context "${CI_PROJECT_DIR}/containers/alg/"
        --dockerfile "${CI_PROJECT_DIR}/containers/alg/Dockerfile"
        --destination "${CI_REGISTRY_IMAGE}/alg/dev:${CI_COMMIT_SHA}"
  except:
    - master

build_exams:
  stage: build
  <<: *dind_config
  <<: *vault_login
  script:
    - vaultenv containers/exams/build.sh
    - docker push "$DOCKER_BASENAME/exams/dev:$CI_COMMIT_SHA"
  except:
    - master

build_vpn:
  stage: build
  <<: *dind_config
  <<: *vault_login
  script:
    - vaultenv containers/vpn/build.sh
    - docker push "$DOCKER_BASENAME/vpn/dev:$CI_COMMIT_SHA"
  except:
    - master

tag-alg:
  <<: *dind_config
  stage: tag
  script:
    - docker pull "$DOCKER_BASENAME/alg/dev:$CI_COMMIT_SHA"
    - docker tag
        "$DOCKER_BASENAME/alg/dev:$CI_COMMIT_SHA"
        "$DOCKER_BASENAME/alg:master"
    - docker push "$DOCKER_BASENAME/alg:master"
  only:
    - master
  except:
    - schedules

tag-exams:
  <<: *dind_config
  stage: tag
  script:
    - docker pull "$DOCKER_BASENAME/exams/dev:$CI_COMMIT_SHA"
    - docker tag
        "$DOCKER_BASENAME/exams/dev:$CI_COMMIT_SHA"
        "$DOCKER_BASENAME/exams:master"
    - docker push "$DOCKER_BASENAME/exams:master"
  only:
    - master
  except:
    - schedules

tag-vpn:
  <<: *dind_config
  stage: tag
  script:
    - docker pull "$DOCKER_BASENAME/vpn/dev:$CI_COMMIT_SHA"
    - docker tag
        "$DOCKER_BASENAME/vpn/dev:$CI_COMMIT_SHA"
        "$DOCKER_BASENAME/vpn:master"
    - docker push "$DOCKER_BASENAME/vpn:master"
  only:
    - master
  except:
    - schedules

deploy_infra:
  stage: deploy
  <<: *dind_config
  <<: *vault_login
  script:
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/terraform.tfstate
        infrastructure/terraform.tfstate ||
        (echo "No previous state found" && NEW_DEPLOY=true)
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/dns/terraform.tfstate
        infrastructure/dns/terraform.tfstate ||
        echo "No previous state for DNS found"
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/staging/terraform.tfstate
        infrastructure/staging/terraform.tfstate ||
        echo "No previous state for staging found"
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/kubeconfig
        $HOME/.kube/config || echo "No Kubernetes configuration file found"
    - sed -i 's/plan/apply\ -auto-approve/g' infrastructure/terraform.sh
    - vaultenv infrastructure/terraform.sh deployment
  after_script:
    - aws s3 cp
        infrastructure/terraform.tfstate
        s3://$FS_S3_BUCKET_NAME/terraform/terraform.tfstate
    - aws s3 cp
        infrastructure/dns/terraform.tfstate
        s3://$FS_S3_BUCKET_NAME/terraform/dns/terraform.tfstate
    - aws s3 cp
        infrastructure/staging/terraform.tfstate
        s3://$FS_S3_BUCKET_NAME/terraform/staging/terraform.tfstate ||
        echo "No previous state for staging found"
    - aws s3 cp
        $HOME/.kube/config
        s3://$FS_S3_BUCKET_NAME/terraform/kubeconfig
    - aws s3 cp
        "$HOME/vault-ca.crt"
        s3://$VAULT_S3_BUCKET/vault-ca.crt
    - rm infrastructure/*.xml
    - docker logout "$CI_REGISTRY"
  only:
    - master
  except:
    - schedules

fluidasserts_post:
  <<: *dind_config
  stage: postdeploy
  script:
    - docker pull fluidattacks/asserts
    - docker run -t -e FA_STRICT="true" -w /code
      -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
      -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
      -v /tmp${CI_PROJECT_DIR}/${CI_COMMIT_SHA}/src:/code
      fluidattacks/asserts asserts /code/asserts/exploit.py
  only:
    - master
  except:
    - schedules

change_keys:
  stage: rotation
  <<: *vault_login
  script:
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/kubeconfig
        $HOME/.kube/config
    - cd infrastructure
    - source vault-wrapper.sh
    - vault_generate_aws_keys integrates-cloudwatch
    - vault_generate_aws_keys integrates-dynamodb
    - vault_generate_aws_keys integrates-s3
    - vault_generate_aws_keys web-s3
    - NEW_JWT_SECRET=$(head -c 32 /dev/urandom | base64)
    - vault_update_variables integrates/development jwt_secret $NEW_JWT_SECRET
    - vault_update_variables integrates/production jwt_secret $NEW_JWT_SECRET
    - export FORMSTACK_EMAIL="$(vault read -field=formstack_email
        secret/serves)"
    - export FORMSTACK_PASS="$(vault read -field=formstack_pass
        secret/serves)"
    - FORMSTACK_TOKENS=`./rotate_fs_keys.py`
    - vault_update_variables integrates/development
        formstack_tokens "$FORMSTACK_TOKENS"
    - vault_update_variables integrates/production
        formstack_tokens "$FORMSTACK_TOKENS"
    - export INTEGRATES_VAULT_TOKEN=$(curl --request POST
        --data '{"role_id":"'"$INTEGRATES_PROD_ROLE_ID"'","secret_id":"'"$INTEGRATES_PROD_SECRET_ID"'"}'
        "https://$VAULT_S3_BUCKET.com/v1/auth/approle/login" |
        jq -r '.auth.client_token')
    - sed -i 's/$FI_VAULT_HOST/'"$(echo -n $VAULT_HOST | base64)"'/;
        s/$FI_VAULT_TOKEN/'"$(echo -n $INTEGRATES_VAULT_TOKEN | base64)"'/'
        eks/manifests/deployments/integrates.yaml
    - sed -i 's/$DATE/'"$(date)"'/' eks/manifests/deployments/*.yaml
    - kubectl apply -f eks/manifests/deployments/integrates.yaml
    - kubectl rollout status deploy/integrates -w
    - python3 -c "from rotate_fs_keys import delete_formstack_tokens;
        delete_formstack_tokens()"
  only:
    - schedules

vault_backup:
  stage: backup
  script:
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/kubeconfig
        $HOME/.kube/config
    - cd infrastructure/eks/manifests/vault/
    - kubectl apply -f backup-operator.yaml
    - kubectl rollout status deploy/vault-etcd-operator-etcd-backup-operator
    - envsubst < credentials > creds
        && mv creds credentials
    - envsubst < config > conf
        && mv conf config
    - kubectl create secret generic aws
        --from-file=credentials
        --from-file=config
    - export DATE=$(date +%Y-%m-%d)
    - envsubst < backup.yaml > backup
        && mv backup backup.yaml
    - kubectl apply -f backup.yaml
    - while ! aws s3 ls s3://$VAULT_S3_BUCKET | grep backup-$(date +%Y-%m-%d);
        do sleep 2;
      done
    - kubectl delete -f backup.yaml
    - kubectl delete secret aws
    - kubectl delete -f backup-operator.yaml
    - rm credentials
  only:
    - schedules

formstack_backup:
  stage: backup
  <<: *vault_login
  script:
    - pip3 install boto3
    - export FORMSTACK_EMAIL="$(vault read -field=formstack_email
        secret/serves)"
    - export FORMSTACK_PASS="$(vault read -field=formstack_pass
        secret/serves)"
    - ./infrastructure/fs_backup.py
  only:
    - schedules
