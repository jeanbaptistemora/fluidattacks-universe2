image: registry.gitlab.com/fluidsignal/serves:builder

before_script:
  - export DOCKER_BASENAME="$CI_REGISTRY/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME"
  - echo "$CI_REGISTRY_PASSWORD" |
        docker login "$CI_REGISTRY" -u "$CI_REGISTRY_USER" --password-stdin

after_script:
  - docker logout "$CI_REGISTRY"

stages:
  - deps
  - analytics
  - test-code
  - test-infra
  - build
  - mr-check
  - tag
  - deploy
  - postdeploy
  - dns
  - rotation
  - backup

.vault_login: &vault_login
  before_script:
    - export VAULT_TOKEN=$(curl --request POST
        --data '{"role_id":"'"$SERVES_ROLE_ID"'","secret_id":"'"$SERVES_SECRET_ID"'"}'
        "https://$VAULT_S3_BUCKET.com/v1/auth/approle/login" |
        jq -r '.auth.client_token')
    - export VAULT_HOST="$VAULT_S3_BUCKET.com"
    - export VAULT_PORT=443
    - export VAULTENV_SECRETS_FILE="$CI_PROJECT_DIR/env.vars"
    - export DOCKER_BASENAME="$CI_REGISTRY/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME"
    - echo "$CI_REGISTRY_PASSWORD" |
        docker login "$CI_REGISTRY" -u "$CI_REGISTRY_USER" --password-stdin

.kaniko_config: &kaniko_config
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  before_script:
    - echo '{"auths":{"'"${CI_REGISTRY}"'":{"username":"'"${CI_REGISTRY_USER}"'","password":"'"${CI_REGISTRY_PASSWORD}"'"}}}'
        > /kaniko/.docker/config.json

.vault_vars: &vault_vars
  variables:
    VAULT_HOST: "${VAULT_S3_BUCKET}.com"
    VAULT_PORT: 443
    VAULT_API_URL: "https://${VAULT_S3_BUCKET}.com/v1/auth/approle/login"
    ROLE_ID: "${SERVES_ROLE_ID}"
    SECRET_ID: "${SERVES_SECRET_ID}"

.kaniko_vault_config: &kaniko_vault_config
  <<: *vault_vars
  <<: *kaniko_config

.dind_config: &dind_config
  variables:
    DOCKER_DRIVER: overlay2
  services:
    - docker:dind

build_base:
  stage: deps
  <<: *kaniko_config
  script:
    - /kaniko/executor
        --context "${CI_PROJECT_DIR}/containers/base/"
        --dockerfile "${CI_PROJECT_DIR}/containers/base/Dockerfile"
        --destination "${CI_REGISTRY_IMAGE}:base"
  only:
    refs:
      - schedules
  except:
    variables:
      - $FLAG_SYNC_CURRENCIES
      - $FLAG_SYNC_FORMSTACK
      - $FLAG_SYNC_AWSDYNAMODB
      - $FLAG_SYNC_TIMEDOCTOR
      - $FLAG_SYNC_GIT
      - $FLAG_SYNC_MANDRILL

build_builder:
  stage: deps
  <<: *kaniko_config
  script:
    - /kaniko/executor
        --context "${CI_PROJECT_DIR}/containers/builder/"
        --dockerfile "${CI_PROJECT_DIR}/containers/builder/Dockerfile"
        --destination "${CI_REGISTRY_IMAGE}:builder"
  only:
    refs:
      - schedules
  except:
    variables:
      - $FLAG_SYNC_CURRENCIES
      - $FLAG_SYNC_FORMSTACK
      - $FLAG_SYNC_AWSDYNAMODB
      - $FLAG_SYNC_TIMEDOCTOR
      - $FLAG_SYNC_GIT
      - $FLAG_SYNC_MANDRILL

test_code:
  stage: test-code
  script:
    - ./check-changed.sh
  except:
    - master

commitlint:
  stage: test-code
  image: starefossen/ruby-node:2-10
  before_script:
    - npm install --unsafe-perm
  script:
    - ./ci-scripts/commitlint-checks.sh
  except:
    - master
    - schedules

test_terraform:
  stage: test-infra
  <<: *vault_login
  script:
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/terraform.tfstate
        infrastructure/terraform.tfstate ||
        echo "No previous state for infrastructure found"
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/dns/terraform.tfstate
        infrastructure/dns/terraform.tfstate ||
        echo "No previous state for DNS found"
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/staging/terraform.tfstate
        infrastructure/staging/terraform.tfstate ||
        echo "No previous state for staging found"
    - vaultenv infrastructure/terraform.sh
  after_script:
    - rm infrastructure/*.xml
    - docker logout "$CI_REGISTRY"
  except:
    - master

build_alg:
  stage: build
  <<: *kaniko_vault_config
  script:
    - cp env.vars containers/alg/
    - /kaniko/executor
        --build-arg VAULT_HOST="${VAULT_HOST}"
        --build-arg VAULT_PORT="${VAULT_PORT}"
        --build-arg VAULT_API_URL="${VAULT_API_URL}"
        --build-arg ROLE_ID="${ROLE_ID}"
        --build-arg SECRET_ID="${SECRET_ID}"
        --context "${CI_PROJECT_DIR}/containers/alg/"
        --dockerfile "${CI_PROJECT_DIR}/containers/alg/Dockerfile"
        --destination "${CI_REGISTRY_IMAGE}/alg/dev:${CI_COMMIT_SHA}"
  except:
    - master

build_exams:
  stage: build
  <<: *dind_config
  <<: *vault_login
  script:
    - vaultenv containers/exams/build.sh
    - docker push "$DOCKER_BASENAME/exams/dev:$CI_COMMIT_SHA"
  except:
    - master

build_vpn:
  stage: build
  <<: *dind_config
  <<: *vault_login
  script:
    - vaultenv containers/vpn/build.sh
    - docker push "$DOCKER_BASENAME/vpn/dev:$CI_COMMIT_SHA"
  except:
    - master

mr-test:
  stage: mr-check
  only:
    - merge_requests
  variables:
    GIT_STRATEGY: clone
  script:
    ./ci-scripts/check-branch.sh

danger:
  stage: mr-check
  image: starefossen/ruby-node:2-10
  variables:
    DANGER_GITLAB_API_TOKEN: ${DANGER_TOKEN}
    DANGER_GITLAB_HOST: "gitlab.com"
    DANGER_GITLAB_API_BASE_URL: "https://gitlab.com/api/v4"
  before_script:
    - export CI_MERGE_REQUEST_ID=$(git ls-remote -q origin merge-requests\*\head
      | grep ${CI_COMMIT_SHA}
      | sed 's/.*refs\/merge-requests\/\([0-9]*\)\/head/\1/g')
    - npm install --unsafe-perm
    - bundle install
  script:
    - bundle exec danger --verbose --fail-on-errors=true
  only:
    - merge_requests

tag-alg:
  <<: *dind_config
  stage: tag
  script:
    - docker pull "$DOCKER_BASENAME/alg/dev:$CI_COMMIT_SHA"
    - docker tag
        "$DOCKER_BASENAME/alg/dev:$CI_COMMIT_SHA"
        "$DOCKER_BASENAME/alg:master"
    - docker push "$DOCKER_BASENAME/alg:master"
  only:
    - master
  except:
    - schedules

tag-exams:
  <<: *dind_config
  stage: tag
  script:
    - docker pull "$DOCKER_BASENAME/exams/dev:$CI_COMMIT_SHA"
    - docker tag
        "$DOCKER_BASENAME/exams/dev:$CI_COMMIT_SHA"
        "$DOCKER_BASENAME/exams:master"
    - docker push "$DOCKER_BASENAME/exams:master"
  only:
    - master
  except:
    - schedules

tag-vpn:
  <<: *dind_config
  stage: tag
  script:
    - docker pull "$DOCKER_BASENAME/vpn/dev:$CI_COMMIT_SHA"
    - docker tag
        "$DOCKER_BASENAME/vpn/dev:$CI_COMMIT_SHA"
        "$DOCKER_BASENAME/vpn:master"
    - docker push "$DOCKER_BASENAME/vpn:master"
  only:
    - master
  except:
    - schedules

deploy_infra:
  stage: deploy
  <<: *dind_config
  <<: *vault_login
  script:
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/terraform.tfstate
        infrastructure/terraform.tfstate ||
        (echo "No previous state found" && NEW_DEPLOY=true)
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/dns/terraform.tfstate
        infrastructure/dns/terraform.tfstate ||
        echo "No previous state for DNS found"
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/staging/terraform.tfstate
        infrastructure/staging/terraform.tfstate ||
        echo "No previous state for staging found"
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/kubeconfig
        $HOME/.kube/config || echo "No Kubernetes configuration file found"
    - sed -i 's/plan/apply\ -auto-approve/g' infrastructure/terraform.sh
    - vaultenv infrastructure/terraform.sh deployment
  after_script:
    - aws s3 cp
        infrastructure/terraform.tfstate
        s3://$FS_S3_BUCKET_NAME/terraform/terraform.tfstate
    - aws s3 cp
        infrastructure/dns/terraform.tfstate
        s3://$FS_S3_BUCKET_NAME/terraform/dns/terraform.tfstate
    - aws s3 cp
        infrastructure/staging/terraform.tfstate
        s3://$FS_S3_BUCKET_NAME/terraform/staging/terraform.tfstate ||
        echo "No previous state for staging found"
    - aws s3 cp
        $HOME/.kube/config
        s3://$FS_S3_BUCKET_NAME/terraform/kubeconfig
    - aws s3 cp
        "$HOME/vault-ca.crt"
        s3://$VAULT_S3_BUCKET/vault-ca.crt
    - rm infrastructure/*.xml
    - docker logout "$CI_REGISTRY"
  only:
    - master
  except:
    - schedules

fluidasserts_post:
  stage: postdeploy
  image: fluidattacks/asserts
  before_script:
    - echo 'Testing the security of the infrastructure...'
  script:
    - asserts asserts/exploit.py
  only:
    - master
  except:
    - schedules

change_keys:
  stage: rotation
  <<: *vault_login
  script:
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/kubeconfig
        $HOME/.kube/config
    - cd infrastructure
    - source vault-wrapper.sh
    - vault_generate_aws_keys integrates-cloudwatch
    - vault_generate_aws_keys integrates-dynamodb
    - vault_generate_aws_keys integrates-s3
    - vault_generate_aws_keys web-s3
    - NEW_JWT_SECRET=$(head -c 32 /dev/urandom | base64)
    - vault_update_variables integrates/development jwt_secret $NEW_JWT_SECRET
    - vault_update_variables integrates/production jwt_secret $NEW_JWT_SECRET
    - export FORMSTACK_EMAIL="$(vault read -field=formstack_email
        secret/serves)"
    - export FORMSTACK_PASS="$(vault read -field=formstack_pass
        secret/serves)"
    - FORMSTACK_TOKENS=`./rotate_fs_keys.py`
    - vault_update_variables integrates/development
        formstack_tokens "$FORMSTACK_TOKENS"
    - vault_update_variables integrates/production
        formstack_tokens "$FORMSTACK_TOKENS"
    - export INTEGRATES_VAULT_TOKEN=$(curl --request POST
        --data '{"role_id":"'"$INTEGRATES_PROD_ROLE_ID"'","secret_id":"'"$INTEGRATES_PROD_SECRET_ID"'"}'
        "https://$VAULT_S3_BUCKET.com/v1/auth/approle/login" |
        jq -r '.auth.client_token')
    - sed -i 's/$FI_VAULT_HOST/'"$(echo -n $VAULT_HOST | base64)"'/;
        s/$FI_VAULT_TOKEN/'"$(echo -n $INTEGRATES_VAULT_TOKEN | base64)"'/'
        eks/manifests/deployments/integrates.yaml
    - sed -i 's/$DATE/'"$(date)"'/' eks/manifests/deployments/*.yaml
    - kubectl apply -f eks/manifests/deployments/integrates.yaml
    - kubectl rollout status deploy/integrates -w
    - python3 -c "from rotate_fs_keys import delete_formstack_tokens;
        delete_formstack_tokens()"
  only:
    refs:
      - schedules
  except:
    variables:
      - $FLAG_SYNC_CURRENCIES
      - $FLAG_SYNC_FORMSTACK
      - $FLAG_SYNC_AWSDYNAMODB
      - $FLAG_SYNC_TIMEDOCTOR
      - $FLAG_SYNC_GIT
      - $FLAG_SYNC_MANDRILL

vault_backup:
  stage: backup
  script:
    - aws s3 cp
        s3://$FS_S3_BUCKET_NAME/terraform/kubeconfig
        $HOME/.kube/config
    - cd infrastructure/eks/manifests/vault/
    - kubectl apply -f backup-operator.yaml
    - kubectl rollout status deploy/vault-etcd-operator-etcd-backup-operator
    - envsubst < credentials > creds
        && mv creds credentials
    - envsubst < config > conf
        && mv conf config
    - kubectl create secret generic aws
        --from-file=credentials
        --from-file=config
    - export DATE=$(date +%Y-%m-%d)
    - envsubst < backup.yaml > backup
        && mv backup backup.yaml
    - kubectl apply -f backup.yaml
    - while ! aws s3 ls s3://$VAULT_S3_BUCKET | grep backup-$(date +%Y-%m-%d);
        do sleep 2;
      done
    - kubectl delete -f backup.yaml
    - kubectl delete secret aws
    - kubectl delete -f backup-operator.yaml
    - rm credentials
  only:
    refs:
      - schedules
  except:
    variables:
      - $FLAG_SYNC_CURRENCIES
      - $FLAG_SYNC_FORMSTACK
      - $FLAG_SYNC_AWSDYNAMODB
      - $FLAG_SYNC_TIMEDOCTOR
      - $FLAG_SYNC_GIT
      - $FLAG_SYNC_MANDRILL

formstack_backup:
  stage: backup
  <<: *vault_login
  script:
    - pip3 install boto3
    - export FORMSTACK_EMAIL="$(vault read -field=formstack_email
        secret/serves)"
    - export FORMSTACK_PASS="$(vault read -field=formstack_pass
        secret/serves)"
    - ./infrastructure/fs_backup.py
  only:
    refs:
      - schedules
  except:
    variables:
      - $FLAG_SYNC_CURRENCIES
      - $FLAG_SYNC_FORMSTACK
      - $FLAG_SYNC_AWSDYNAMODB
      - $FLAG_SYNC_TIMEDOCTOR
      - $FLAG_SYNC_GIT
      - $FLAG_SYNC_MANDRILL

sync_currencies:
  stage: analytics
  <<: *vault_login
  script:
    - pip3 install
        analytics/singer/tap_currencyconverterapi
        analytics/singer/target_redshift
    - tap-currencyconverterapi > /currencies.singer
    - echo "$(vault read -field=analytics_auth_redshift secret/serves)" > /target_secret.json
    - cat /currencies.singer |
        target-redshift --auth /target_secret.json --drop-schema --schema-name "currencies"
    - rm -fr /target_secret.json
  only:
    refs:
      - schedules
    variables:
      - $FLAG_SYNC_CURRENCIES

sync_formstack:
  stage: analytics
  <<: *vault_login
  script:
    - mkdir /logs
    - pip3 install
        analytics/singer/tap_formstack
        analytics/singer/target_redshift
    - echo "$(vault read -field=analytics_auth_formstack secret/serves)" > /tap_secret.json
    - echo "$(vault read -field=analytics_auth_redshift secret/serves)" > /target_secret.json
    - tap-formstack --auth /tap_secret.json --conf analytics/conf/formstack.json |
      target-redshift --auth /target_secret.json --drop-schema --schema-name "formstack"
    - rm -fr /tap_secret.json /target_secret.json
  only:
    refs:
      - schedules
    variables:
      - $FLAG_SYNC_FORMSTACK

sync_awsdynamodb:
  stage: analytics
  <<: *vault_login
  script:
    - mkdir /logs
    - pip3 install
        analytics/singer/tap_awsdynamodb
        analytics/singer/target_redshift
    - echo '{ "AWS_ACCESS_KEY_ID":"'$(vault read
        -field=aws_dynamodb_access_key secret/serves)'",
              "AWS_SECRET_ACCESS_KEY":"'$(vault read
        -field=aws_dynamodb_secret_key secret/serves)'",
              "AWS_DEFAULT_REGION":"'$(vault read
        -field=aws_dynamodb_default_region secret/serves)'"}' > /tap_secret.json
    - echo "$(vault read -field=analytics_auth_redshift secret/serves)" > /target_secret.json
    - tap-awsdynamodb --auth /tap_secret.json --conf analytics/conf/awsdynamodb.json |
      target-redshift --auth /target_secret.json --drop-schema --drop-tables --schema-name "dynamodb"
    - rm -fr /tap_secret.json /target_secret.json
  only:
    refs:
      - schedules
    variables:
      - $FLAG_SYNC_AWSDYNAMODB

sync_timedoctor:
  stage: analytics
  <<: *vault_login
  script:
    - mkdir /logs
    - pip3 install
        boto3
        analytics/singer/tap_timedoctor
        analytics/singer/target_redshift
    - echo '{ "AWS_ACCESS_KEY_ID":"'$(vault read
        -field=aws_s3_access_key secret/serves)'",
              "AWS_SECRET_ACCESS_KEY":"'$(vault read
        -field=aws_s3_secret_key secret/serves)'",
              "AWS_DEFAULT_REGION":"'$(vault read
        -field=aws_s3_default_region secret/serves)'"}' > /s3_auth.json
    - echo "$(vault read -field=analytics_s3_cache_timedoctor secret/serves)" > /s3_files.json
    - echo "$(vault read -field=analytics_auth_timedoctor secret/serves)" > /tap_secret.json
    - echo "$(vault read -field=analytics_auth_redshift secret/serves)" > /target_secret.json
    - python3 analytics/download_from_aws_sss.py -auth /s3_auth.json -conf /s3_files.json
    - mv timedoctor.worklogs.2013-2016.singer timedoctor.singer
    - tap-timedoctor -auth /tap_secret.json >> timedoctor.singer
    - cat timedoctor.singer |
        target-redshift --auth /target_secret.json --drop-schema --schema-name "timedoctor"
    - rm -fr /s3_auth.json /s3_files.json /tap_secret.json /target_secret.json
  only:
    refs:
      - schedules
    variables:
      - $FLAG_SYNC_TIMEDOCTOR

sync_git:
  stage: analytics
  <<: *vault_login
  script:
    - mkdir ~/.ssh
    - pip3 install
        pyyaml
        analytics/singer/tap_git
        analytics/singer/target_redshift
    - analytics/git/set_awscli.sh
    - python3 analytics/git/clone_us.py 2>&1 | aws s3 cp - s3://fluidanalytics/clone_us.log
    - python3 analytics/git/clone_them.py 2>&1 | aws s3 cp - s3://fluidanalytics/clone_them.log
    - python3 analytics/git/generate_config.py 2>&1 | aws s3 cp - s3://fluidanalytics/generate_config.log
    - analytics/git/sync_forked.sh
    - rm -fr ~/.aws/{credentials, config}
  only:
    refs:
      - schedules
    variables:
      - $FLAG_SYNC_GIT

sync_mandrill:
  stage: analytics
  <<: *vault_login
  script:
    - pip3 install
        analytics/singer/streamer_mandrill
        analytics/singer/tap_json
        analytics/singer/target_redshift
    - echo "$(vault read -field=analytics_auth_mandrill secret/serves)" > /stream_secret.json
    - echo "$(vault read -field=analytics_auth_redshift secret/serves)" > /target_secret.json
    - streamer-mandrill --auth /stream_secret.json > mandrill.jsonstream
    - cat mandrill.jsonstream | tap-json > mandrill.singer
    - cat mandrill.singer | target-redshift --auth /target_secret.json --drop-schema --schema-name "mandrill"
    - rm -rf /stream_secret.json /target_secret.json
  only:
    refs:
      - schedules
    variables:
      - $FLAG_SYNC_MANDRILL
