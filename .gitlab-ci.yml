image: registry.gitlab.com/fluidsignal/web:base

stages:
  - build
  - lint
  - review
  - deployment

builder:
  image: docker:17
  services:
    - docker:dind
  stage: build
  script:
    - docker login $CI_REGISTRY -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD
    - docker pull $CI_REGISTRY/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME:base
    # Only builds from scratch if the Dockerfile has changed
    - docker build --cache-from $CI_REGISTRY/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME:base
      -t $CI_REGISTRY/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME:base builder/
    - docker push $CI_REGISTRY/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME:base

checks:
  stage: lint
  services:
    - docker:dind
  script:
    - if curl --fail -Lo artifacts.zip --header Private-Token:$DOCKER_PASSWD https://gitlab.com/api/v4/projects/$CI_PROJECT_ID/jobs/artifacts/$CI_COMMIT_REF_NAME/download?job=$CI_JOB_NAME; then unzip artifacts.zip && rm artifacts.zip; else echo "There are no artifacts"; fi
    - ./check-changed.sh
    - ./check-all.sh
    - ./check-articles.sh
    - ./sass-lint.sh
    - pybabel compile --directory theme/2014/translations/ --domain messages
    - for FILE in $(find . -iname '*.adoc'); do sed -i 's/^include::/include::\/builds\/fluidsignal/g' $FILE; done
    - sed -i 's/https:\/\/fluidattacks\.com/http:\/\/'"$KUBE_IP\/$CI_COMMIT_REF_SLUG"'/g' pelicanconf.py
    - pelican --fatal errors --fatal warnings content/
    - mv output/web/en/blog-en/* output/web/en/blog && mv output/web/es/blog-es/* output/web/es/blog
    - ./xmlcombine.sh
    - cp -r output/web/es/pages-es/* output/web/es/ && rm -rf output/web/es/pages-es
    - cp -r output/web/en/pages-en/* output/web/en/ && rm -rf output/web/en/pages-en
    - mv output/web/en/redirect/index.html output/web/ && rmdir output/web/en/redirect/
    - mv robots.txt output/web/
    - rm -rf output/web/de
    - ./html-lint.sh
    - mkdir -p review/output/$CI_COMMIT_REF_SLUG/
    - mv output/web review/output/$CI_COMMIT_REF_SLUG/
    - docker login $CI_REGISTRY -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD
    - docker build --no-cache -t $CI_REGISTRY/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME:$CI_COMMIT_REF_SLUG review/
    - docker push $CI_REGISTRY/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME:$CI_COMMIT_REF_SLUG
    - rm -rf output/ && rm -rf review/output
  artifacts:
    untracked: true
    when: on_success
    expire_in: 18 hrs
    paths:
      - cache/
  except:
    - master

review-web:
  stage: review
  image: lwolf/kubectl_deployer
  script:
    - ./review/cluster-config.sh
  environment:
    name: review/$CI_COMMIT_REF_SLUG
    url: http://$KUBE_IP/$CI_COMMIT_REF_SLUG/web/en/
    on_stop: stop-review
  except:
    - master

stop-review:
  stage: review
  image: lwolf/kubectl_deployer
  variables:
    GIT_STRATEGY: none
  script:
    - kubectl config set-context $(kubectl config current-context) --namespace=gitlab-managed-apps
    - kubectl delete deployment review-$CI_COMMIT_REF_SLUG
    - kubectl delete service web-service-$CI_COMMIT_REF_SLUG;
    - kubectl get ingress ingress-review -o yaml | tac | sed '/\/'"$CI_COMMIT_REF_SLUG"'/,+3d' | tac > current-ingress.yaml
    - kubectl delete ingress ingress-review
    - kubectl create -f current-ingress.yaml
  when: manual
  environment:
    name: review/$CI_COMMIT_REF_SLUG
    action: stop

pages:
  stage: deployment
  environment: staging
  script:
    - if curl --fail -Lo artifacts.zip --header Private-Token:$DOCKER_PASSWD https://gitlab.com/api/v4/projects/$CI_PROJECT_ID/jobs/artifacts/$CI_COMMIT_REF_NAME/download?job=deploy; then unzip artifacts.zip; else echo "There are no artifacts"; fi
    - sed -i 's/output\/web/public/g' xmlcombine.sh
    - sed -i 's/output/public/g' html-lint.sh draft.sh
    - for FILE in $(find . -iname '*.adoc'); do sed -i 's/^include::/include::\/builds\/fluidsignal/g' $FILE; done
    - pelican --fatal errors --fatal warnings -s pelicanconf-2018.py content/
    - ./xmlcombine.sh
    - mv public/en/blog-en public/en/blog && mv public/es/blog-es public/es/blog
    - cp -r public/es/pages-es-2018/* public/es/ && rm -rf public/es/pages-es-2018
    - cp -r public/en/pages-en-2018/* public/en/ && rm -rf public/en/pages-en-2018
    - mv public/en/redirect/index.html public/ && rmdir public/en/redirect/
    - ./draft.sh
  artifacts:
    paths:
      - public
  only:
    - master

deploy:
  stage: deployment
  environment: production
  script:
    # Download cache from previous builds
    - if curl --fail -Lo artifacts.zip --header Private-Token:$DOCKER_PASSWD https://gitlab.com/api/v4/projects/$CI_PROJECT_ID/jobs/artifacts/$CI_COMMIT_REF_NAME/download?job=$CI_JOB_NAME; then unzip artifacts.zip && rm artifacts.zip; else echo "There are no artifacts"; fi
    # Generate file for localization of the site
    - pybabel compile --directory theme/2014/translations/ --domain messages
    # Fix links to successfully include files
    - for FILE in $(find . -iname '*.adoc'); do sed -i 's/^include::/include::\/builds\/fluidsignal/g' $FILE; done
    # Generate the website, exiting on any error encountered
    - pelican --fatal errors --fatal warnings content/
    # Remove dummy folder used to translate messages to english as well
    - rm -rf output/web/de
    # Give the folders, named after the language of its content, a general name in each subsite
    - mv output/web/en/blog-en/* output/web/en/blog && mv output/web/es/blog-es/* output/web/es/blog
    # Script to generate a complete sitemap of the site
    - ./xmlcombine.sh
    # Remove the language identification used to group documents and images in the same directory
    - cp -r output/web/es/pages-es/* output/web/es/ && rm -rf output/web/es/pages-es
    - cp -r output/web/en/pages-en/* output/web/en/ && rm -rf output/web/en/pages-en
    # Set the redirect from web/ to web/en/
    - mv output/web/en/redirect/index.html output/web/ && rmdir output/web/en/redirect/
    # Set robots.txt
    - mv robots.txt output/web/
    # Organize images of articles with draft status
    - ./draft.sh
    # Upload content to S3 bucket
    - aws s3 cp --recursive --acl public-read output/web/ "s3://$S3_BUCKET_NAME/webnew"
    # Change the name of the current folder in production
    - aws s3 mv --recursive "s3://$S3_BUCKET_NAME/web" "s3://$S3_BUCKET_NAME/webold"
    # Change the name of the new folder passed to production
    - aws s3 mv --recursive "s3://$S3_BUCKET_NAME/webnew" "s3://$S3_BUCKET_NAME/web"
    # Erase content of the S3 bucket
    - aws s3 rm --recursive "s3://$S3_BUCKET_NAME/webold" && aws s3 rm "s3://$S3_BUCKET_NAME/web"
    # Set 301 redirects
    - ./amz-redirect.sh
    # Erase output folder to reduce artifact size since it is untracked
    - rm -rf output/
  artifacts:
    untracked: true
    when: on_success
    expire_in: 18 hrs
    paths:
      - cache/
  only:
    - master
